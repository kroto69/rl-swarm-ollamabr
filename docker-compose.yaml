services:
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile.webserver
    environment:
      - OTEL_SERVICE_NAME=rlswarm-fastapi
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
    depends_on:
      - otel-collector
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/healthz"]
      interval: 30s
      retries: 3

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.120.0
    ports:
      - "4317:4317"
      - "4318:4318"
    environment:
      - OTEL_LOG_LEVEL=DEBUG
    healthcheck:
      test: ["CMD", "grpc_health_probe", "-addr=localhost:4317"]
      interval: 5s
      retries: 5

  swarm-cpu:
    profiles: ["swarm"]
    build:
      context: .
      dockerfile: containerfiles/swarm-node/swarm.containerfile
      args:
        - BASE_IMAGE=ubuntu:24.04
    depends_on:
      - otel-collector
    ports:
      - "3000:3000"
    # 1. JEMBATAN KE HOST (Agar docker bisa panggil localhost laptop)
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./code_gen_exp:/home/gensyn/rl_swarm/code_gen_exp 
      - ./user/modal-login:/home/gensyn/rl_swarm/modal-login/temp-data
      - ./user/keys:/home/gensyn/rl_swarm/keys
      - ./user/configs:/home/gensyn/rl_swarm/configs
      - ./user/logs:/home/gensyn/rl_swarm/logs
    
    environment:
      - HF_TOKEN=${HF_TOKEN}
      
      # --- CPU & THREAD LIMITS ---
      - OMP_NUM_THREADS=5
      - MKL_NUM_THREADS=5
      - TORCH_NUM_THREADS=5
      - RAY_DEDICATED_CPU_CORES=5
      
      # --- NETWORK FIX ---
      - HIVEMIND_USE_IPV6=0
      - HIVEMIND_USE_LOCALHOST=0
      
      # --- OLLAMA FIX (WAJIB ADA) ---
      # Memberitahu script python: "Jangan cari Ollama di dalam container,
      # tapi cari di IP Host lewat pintu belakang."
      - OLLAMA_HOST=http://host.docker.internal:11434

    deploy:
      resources:
        limits:
          cpus: '6.0'
          memory: 30G
  swarm-gpu:
    profiles: ["swarm"]
    build:
      context: .
      dockerfile: containerfiles/swarm-node/swarm.containerfile
      args:
        - BASE_IMAGE=nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04
    depends_on:
      - ollama
    ports:
      - 3000:3000
    volumes:
      - ./user/modal-login:/home/gensyn/rl_swarm/modal-login/temp-data
      - ./user/keys:/home/gensyn/rl_swarm/keys
      - ./user/configs:/home/gensyn/rl_swarm/configs
      - ./user/logs:/home/gensyn/rl_swarm/logs
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - GENSYN_RESET_CONFIG=${GENSYN_RESET_CONFIG}
      - OLLAMA_HOST=http://ollama:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
